{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcPUZoAHJvsl"
   },
   "source": [
    "# Task 6 \n",
    "\n",
    "Subtasks:\n",
    "\n",
    "a) Create a server-side deactivatable system to pseudonymize data;\n",
    "\n",
    "b) Create a dictionary of recurrent single words and n-grams of two, three or more words (typical sentences used) from governmental databases on sexual harassment, newspaper and laws about the issues, better from Nigeria;\n",
    "\n",
    "c)  Classify sentences;\n",
    "\n",
    "d) Create a server-side deactivatable system to allow human control.\n",
    "\n",
    "\n",
    "## Subtask b) -- Create a dictionary of rilevant single words and n-grams of two, three or more words (typical sentences used) from datasets or corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aNP2n1IaLa-5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open dictionary\n",
    "\n",
    "def openDictionary(file):\n",
    "    f = open(file,'r')\n",
    "    text = f.read()       \n",
    "    dictio = ast.literal_eval(text)\n",
    "    f.close()\n",
    "    #print('length =',len(dictio))\n",
    "    #print(type(dictio))\n",
    "    #print(dictio)\n",
    "    return dictio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for unbalanced parentheses in dictiory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dictionaries/female.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-87cbb4f211db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Driver code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./dictionaries/female.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dictionaries/female.txt'"
     ]
    }
   ],
   "source": [
    "# Python3 code to Check for \r\n",
    "# balanced parentheses in an expression\r\n",
    "def check(my_string):\r\n",
    "\r\n",
    "    \r\n",
    "    \r\n",
    "    \r\n",
    "    brackets = ['()', '{}', '[]']\r\n",
    "    while any(x in my_string for x in brackets):\r\n",
    "        for br in brackets:\r\n",
    "            my_string = my_string.replace(br, '')\r\n",
    "    return not my_string\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Driver code\r\n",
    "\r\n",
    "f = open('./dictionaries/female.txt','r')\r\n",
    "text = f.readlines()\r\n",
    "\r\n",
    "for line in text:\r\n",
    "    print(line)\r\n",
    "    pattern = r\"[a-z]|[-.*?\\s\\\\':,|]|[1-9]\"\r\n",
    "    strg = re.sub(pattern, '', line )\r\n",
    "    print(strg)\r\n",
    "    print(strg, \"-\", \"Balanced\" \r\n",
    "      if check(strg) else \"Unbalanced\")\r\n",
    "    print('...............')\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priotizing by source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_source = {\n",
    "    'youtube':3,\n",
    "    'facebook':2,\n",
    "    'tweeter':2,\n",
    "    'news':3,\n",
    "    'linkedin':3,\n",
    "    'stories':2,\n",
    "    'help_center':1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the dataframe by file name, column and source\n",
    "def openDf(file_name, column, source, source_priority, homogeneity):\n",
    "    \n",
    "    #open the file \n",
    "    datafile = pd.read_csv(file_name)\n",
    "    \n",
    "    #select the column with text\n",
    "    df = datafile.loc[:,[column]]\n",
    "    \n",
    "    #rename column with text\n",
    "    df.rename(columns = {column :'body'}, inplace = True)\n",
    "    \n",
    "    # take into account the source and homogeneity\n",
    "    df['source'] = \"\"\n",
    "    df['source_priority'] = \"\"\n",
    "    df['homogeneity'] = \"\"\n",
    "    \n",
    "    #row by row, source and source_priority declaration \n",
    "    for index, row in df.iterrows():\n",
    "        row['source'] = source\n",
    "        row['source_priority'] = source_priority\n",
    "        row['homogeneity'] = homogeneity\n",
    "\n",
    "        \n",
    "    #move columns\n",
    "    df = df[['homogeneity', 'source', 'source_priority','body']]\n",
    "    \n",
    "    # create columns to manage tags and weights\n",
    "    df['tags_a'] = \"\"\n",
    "    df['sum_wgts_a'] = \"\"\n",
    "    df['tags_b'] = \"\"\n",
    "    df['sum_wgts_b'] = \"\"    \n",
    "    df['tags_c'] = \"\"\n",
    "    df['sum_wgts_c'] = \"\"  \n",
    "    df['tags_other'] = \"\" \n",
    "\n",
    "\n",
    "    # create columns to manage joint tags and joint weights\n",
    "    df['tags_ab'] = \"\"\n",
    "    df['sum_wgts_ab'] = \"\"\n",
    "    df['tags_bc'] = \"\"\n",
    "    df['sum_wgts_bc'] = \"\"\n",
    "    \n",
    "    # create columns to in & out  \n",
    "    df['tags_f'] = \"\" \n",
    "    df['inout'] = \"\"\n",
    "    \n",
    "    # create columns to prioritize by source and by violence's type\n",
    "    df['violence_type'] = \"\"\n",
    "\n",
    "    df['priority'] = \"\"    \n",
    "       \n",
    "    #sum tags and weights of ab,bc and c\n",
    "    df['tot_tags'] = \"\"\n",
    "    df['tot_wgts'] = \"\"\n",
    "    \n",
    "    #lenghts of text criteria\n",
    "    df['text_len_criteria'] = \"\"\n",
    "    \n",
    "    # create column to manage validation, reports and delete columns\n",
    "    df['val'] = \"\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tags from dictionary\n",
    "def tagging(vocab):\n",
    "    \n",
    "    tags = []\n",
    "    weights = []\n",
    "\n",
    "    # search amongs fundWords\n",
    "    for key,value in vocab.items():\n",
    "        \n",
    "        # if terms in row\n",
    "        if re.findall(key, row.body):\n",
    "            \n",
    "            #append tags\n",
    "            tags.append(value[1])\n",
    "            #append weights\n",
    "            weights.append(value[0])\n",
    "            \n",
    "    #delete duplicate tags    \n",
    "    tags_cleaned = list(dict.fromkeys(tags))\n",
    "    \n",
    "    #sum weights      \n",
    "    weights_summed = sum(weights)\n",
    "    \n",
    "    #return list of tags and weights\n",
    "    return tags_cleaned, weights_summed\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging_other(vocab):\n",
    "    \n",
    "    tags = []\n",
    "\n",
    "\n",
    "    # search amongs fundWords\n",
    "    for key in vocab:\n",
    "        \n",
    "        # if terms in row\n",
    "        if re.findall(key, row.body):\n",
    "            \n",
    "            #append tags\n",
    "            tags.append(key)\n",
    "            \n",
    "    #delete duplicate tags    \n",
    "    tags_cleaned = list(dict.fromkeys(tags))\n",
    "    \n",
    "    #return list of tags and weights\n",
    "    return tags_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging_c(vocab):\n",
    "  \n",
    "    #prepare lists\n",
    "    tags = []\n",
    "    weights = []\n",
    "    \n",
    "    #word frequency\n",
    "    word_counter = Counter(row['body'].split())\n",
    "    \n",
    "    #word by word \n",
    "    for w, v in word_counter.items():\n",
    "        \n",
    "        #terms by terms in dictionary 3 \n",
    "        for i in vocab:\n",
    "            \n",
    "            #if terms in row\n",
    "            if re.findall(i, w):\n",
    "                \n",
    "                #append tags\n",
    "                tags.append((w,v))\n",
    "                #append weights\n",
    "                weights.append(v)\n",
    "    \n",
    "    #sort tags in base to its value \n",
    "    from operator import itemgetter, attrgetter    \n",
    "    tags_sorted = sorted(tags, key=itemgetter(1), reverse=True)\n",
    "\n",
    "    #sum weights      \n",
    "    weights_summed = sum(weights)\n",
    "    \n",
    "    return tags_sorted, weights_summed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort dataframe\n",
    "def sort_by(column, asc):\n",
    "    df.sort_values(by=column, ascending=True, inplace=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop row by index\n",
    "def drop_row(index_list):\n",
    "    print('are you sure of deleting the following row?', index_list)\n",
    "    x = input()\n",
    "    if x == 'y':\n",
    "        df.drop(index_list, inplace=True)\n",
    "        print('deleted', index_list)\n",
    "    else: sys.exit()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save report by name\n",
    "def df_report(report_name, df_name):\n",
    "    with open(report_name, 'w') as f:\n",
    "        for index, row in df_name.iterrows():\n",
    "            f.write('\\n**********************************************\\n')\n",
    "            f.write(str(index))\n",
    "            f.write('-|-')\n",
    "            f.write(row.body)\n",
    "            f.write('\\n')\n",
    "            f.write('----------IN & OUT------------\\n')\n",
    "            f.write(' '.join([str(elem) for elem in row.inout]))\n",
    "            f.write('\\n')\n",
    "            f.write('----------tags_a------------\\n')\n",
    "            f.write(' '.join([str(elem) for elem in row.tags_a]))\n",
    "            f.write('\\n')\n",
    "            f.write('----------tags_b------------\\n')\n",
    "            f.write(' '.join([str(elem) for elem in row.tags_b]))        \n",
    "            f.write('\\n')\n",
    "            f.write('----------tags_f------------\\n')\n",
    "            f.write(' '.join([str(elem) for elem in row.tags_f]))        \n",
    "            f.write('\\n')\n",
    "            f.write('----------tags_c------------\\n')\n",
    "            f.write(' '.join([str(elem) for elem in row.tags_c]))        \n",
    "            f.write('\\n')\n",
    "            f.write('----------tags_other------------\\n')\n",
    "            f.write(' '.join([str(elem) for elem in row.tags_other]))        \n",
    "            f.write('\\n')            \n",
    "            #f.write('----------tags_ab------------\\n')\n",
    "            #f.write(' '.join([str(elem) for elem in row.tags_ab]))  \n",
    "            #f.write('\\n')\n",
    "            #f.write('----------tags_bc------------\\n')\n",
    "            #f.write(' '.join([str(elem) for elem in row.tags_bc])) \n",
    "            #f.write('\\n')\n",
    "            f.write('----------tot_tags------------\\n')\n",
    "            f.write(' '.join([str(elem) for elem in row.tot_tags]))\n",
    "            f.write('\\n')\n",
    "            f.write('----------tot_wgts------------\\n')\n",
    "            f.write(str(row.tot_wgts))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control the file by name, row index and drop rows by val\n",
    "def human_control(df_name, row_index):\n",
    "    \n",
    "    #open the file \n",
    "    df = pd.read_csv(df_name)\n",
    "    \n",
    "    # set starting index\n",
    "    row_index = int\n",
    "    \n",
    "    list_index = []\n",
    "\n",
    "    #row by row\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        print('\\n**********************************************\\n')\n",
    "        \n",
    "        print(row_index)\n",
    "        print(row.body)\n",
    "        print('\\n')\n",
    "        print('----------IN & OUT------------\\n')\n",
    "        print(' '.join([elem for elem in row.inout]))\n",
    "        print('\\n')\n",
    "        print('----------tags_a------------\\n')\n",
    "        print(' '.join([elem for elem in row.tags_a]))\n",
    "        print('\\n')\n",
    "        print('----------tags_b------------\\n')\n",
    "        print(' '.join([str(elem) for elem in row.tags_b]))        \n",
    "        print('\\n')\n",
    "        print('----------tags_f------------\\n')\n",
    "        print(' '.join([str(elem) for elem in row.tags_f]))   \n",
    "        print('\\n')\n",
    "        print('----------tags_c------------\\n')\n",
    "        print(' '.join([str(elem) for elem in row.tags_c]))   \n",
    "        print('\\n')\n",
    "        print('----------tags_other------------\\n')\n",
    "        print(' '.join([str(elem) for elem in row.tags_other]))        \n",
    "        print('\\n')\n",
    "        #print('----------tags_ab------------\\n')\n",
    "        #print(' '.join([str(elem) for elem in row.tags_ab]))  \n",
    "        #print('\\n')\n",
    "        #print('----------tags_bc------------\\n')\n",
    "        #print(' '.join([str(elem) for elem in row.tags_bc])) \n",
    "        #print('\\n')\n",
    "        #print('----------tot_tags------------\\n')\n",
    "        #print(' '.join([str(elem) for elem in row.tot_tags]))\n",
    "        #print('\\n')\n",
    "        print('----------tot_wgts------------\\n')\n",
    "        print(row.tot_wgts)\n",
    "        print('\\n')\n",
    "        print(row.index)        \n",
    "        print('\\n')\n",
    "        print('row in the list for changes or deletions?')\n",
    "        print('y/n or exit with any other character')\n",
    "        x = input()\n",
    "        \n",
    "        if x == 'y' or x == 'n':\n",
    "            row['val'] = x\n",
    "            if x == 'y':\n",
    "                list_index.append('row_index')            \n",
    "        else:\n",
    "            sys.exit()\n",
    "            \n",
    "    print(list_index)\n",
    "    return list_index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe with name\n",
    "def save_df(name):   \n",
    "    \n",
    "    df.to_csv(name)\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem: homogeneous (dataset is only about women and violence against them) / inhomogeneous dataset is about women, men, lgbt groups, mental illnesses, economy, finance, politics)\n",
    "\n",
    "\n",
    "## solution: two paths, one for homogeneous dataset, one for inhomogeneous dataset (we need to understand if the story is about violence against women) \n",
    "\n",
    "\n",
    "## problem: different sources (facebook, tweeter, youtube, etc...) can have affect about priorities \n",
    "\n",
    "## solution: to prioritize sources\n",
    "\n",
    "\n",
    "## problem: the fundamental terms are few, understanding the context is difficult even for a human\n",
    "\n",
    "## solution: build dictionaries using regular expression massively\n",
    "\n",
    "\n",
    "\n",
    "## I.E. - words used to identify abuse and genital mutilations :\n",
    "\n",
    "## '(abus(e|ed|es|ing|ive|ives|ived) (wo(man|men)|gir(l|ls)|femal(e|es)|girlfrien(d|ds)|lad(y|ies)|her))':(10, 'in general, abuses'),\n",
    "\n",
    "## '(abus(e|ed|es|ing|ive|ives|ived) against (wo(man|men)|gir(l|ls)|femal(e|es)|girlfrien(d|ds)|wif(e|es)|spous(e|es|al)|lad(y|ies)|her))':(10, 'in general, abuses'),\n",
    "\n",
    "## '((wo(man|men)|gir(l|ls)|femal(e|es)|girlfrien(d|ds)|lad(y|ies)|her) abus.*?\\s)':(10, 'in general, abuses'),\n",
    "\n",
    "## '((spou(se|ses|sal|sals)|wif(e|es)|married) abus.*?\\s)':(10, 'spousal abuse'),\n",
    "\n",
    "## '(circumcis(ed|ing|e|es|ion|ions) (wo(man|men)|gir(l|ls)|femal(e|es)|girlfrien(d|ds)|wif(e|es)|spous(e|es|al)|lad(y|ies)|her))':(10, 'genital mutilation'),\n",
    "\n",
    "## '((wo(man|men)|gir(l|ls)|femal(e|es)|girlfrien(d|ds)|wif(e|es)|spous(e|es|al)|lad(y|ies)|her) circumcis.*?\\s)':(10, 'genital mutilation'),\n",
    "\n",
    "## '((wo(man|men)|gir(l|ls)|femal(e|es)|girlfrien(d|ds)|wif(e|es)|spous(e|es|al)|lad(y|ies)|her) genital mutilat.*?\\s)':(10, 'genital mutilation'),\n",
    "\n",
    "## '((wo(man|men)|gir(l|ls)|femal(e|es)|girlfrien(d|ds)|wif(e|es)|spous(e|es|al)|lad(y|ies)|her) genital cut.*?\\s)':(10, 'genital mutilation'),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of terms that identify violence against women in combination with other terms\n",
    "# i.e.\n",
    "fundWords = openDictionary('./dictionaries/fundamentalWords.txt')\n",
    "\n",
    "# Vocabulary of terms that might identify violence against women in combination with other terms\n",
    "#i.e abusive marriage with sex, sexual, she, girl, girls, woman, women,lady, ladies, violence\n",
    "impWords = openDictionary('./dictionaries/importantWords.txt')\n",
    "\n",
    "#female terms \n",
    "female = openDictionary('./dictionaries/female.txt')\n",
    "\n",
    "\n",
    "#other terms (potremmo inserire posti geografici o malattie come hiv, aids, etc...)\n",
    "word_list = openDictionary('./dictionaries/wordList.txt')\n",
    "\n",
    "#other terms (potremmo inserire posti geografici o malattie come hiv, aids, etc...)\n",
    "other = openDictionary('./dictionaries/others.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of terms that identify violence against women in combination with other terms\n",
    "# i.e.\n",
    "fundWords = openDictionary('./dictionaries/fundamentalWords.txt')\n",
    "\n",
    "# Vocabulary of terms that might identify violence against women in combination with other terms\n",
    "#i.e abusive marriage with sex, sexual, she, girl, girls, woman, women,lady, ladies, violence\n",
    "impWords = openDictionary('./dictionaries/importantWords.txt')\n",
    "\n",
    "#female terms \n",
    "female = openDictionary('./dictionaries/female.txt')\n",
    "\n",
    "\n",
    "#other terms (potremmo inserire posti geografici o malattie come hiv, aids, etc...)\n",
    "word_list = openDictionary('./dictionaries/wordList.txt')\n",
    "\n",
    "#other terms (potremmo inserire posti geografici o malattie come hiv, aids, etc...)\n",
    "other = openDictionary('./dictionaries/others.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe\n",
    "\n",
    "## when we build the dataset we need to take into account the source and homogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to prioritize sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what part of the dataset contains the text to be analyzed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set facebook dataset file name, column and source\n",
    "\n",
    "dtfrm = pd.read_csv('youtube_transcripts(copia).csv')\n",
    "\n",
    "print(list(dtfrm))\n",
    "dtfrm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set df by file name, column and source\n",
    "df = openDf('youtube_transcripts(copia).csv', 'transcript', 'youtube transcripts', 3, 'inhomogeneous')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem: having an overall view of what the text is about \n",
    "\n",
    "## solution: tagging using individual dictionaries\n",
    "\n",
    "## - tags_a tells us if a text deals with violence against women for sure.\n",
    "## - tags_b identifies forms of violence that can be against women.\n",
    "## - tags_f is used to confirm that the violence of tag_b can be against women.\n",
    "## - tags_c gives an overall view of what the text is about \n",
    "## - tags_other can be used to eventually cross-reference data. For example, we might be interested in cross-referencing domestic violence data with particular regions of nigeria or with covid. The 'other.text' dictionary might contain words about regions of nigeria or covid.\n",
    "\n",
    "## problems: to prioritize records with more information.\n",
    "\n",
    "## solution: to use word values in the dictionary to give a weight to that word and then sort data by highest score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing Text\n",
    "\n",
    "#clean text from emojoy\n",
    "#print(df['body'].iloc[1])\n",
    "df['body'] = df['body'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)\n",
    "#print('---------------')\n",
    "#print(df['body'].iloc[1])\n",
    "\n",
    "# delete nan row\n",
    "df.dropna(subset = [\"body\"], inplace=True)\n",
    "\n",
    "# delete duplicates\n",
    "df.drop_duplicates(subset=['body'], inplace=True)\n",
    "\n",
    "#ignore case\n",
    "df['body'] = df['body'].str.lower()\n",
    "\n",
    "\n",
    "#print(df['body'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tags_a tells us if a text deals with violence against women for sure.\n",
    "### tags_b identifies forms of violence that can be against women.\n",
    "### tags_c is used to confirm that the violence of tag_b can be against women.\n",
    " \n",
    "\n",
    "#row by row\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "   \n",
    "    #create and insert tags in tags_a\n",
    "    row['tags_a'] = tagging(fundWords)[0]    \n",
    "    # sum_wgts_a assigns a weight to tags_a so that the higher the score, the more important the story \n",
    "    row['sum_wgts_a'] =  tagging(fundWords)[1]\n",
    "    # to join tags_a and tags_b we create and insert tags_a in tags_ab \n",
    "    row['tags_ab'] = tagging(fundWords)[0]\n",
    "    \n",
    "    #create and insert tags in tags_b    \n",
    "    row['tags_b'] = tagging(impWords)[0]\n",
    "    # to join tags_b and tags_c we create and insert tags_b in tags_bc \n",
    "    row['tags_bc'] = tagging(impWords)[0]\n",
    "    ## sum_wgts_b assigns a weight to tags_b so that the higher the score, the more important the story\n",
    "    row['sum_wgts_b'] =  tagging(impWords)[1]\n",
    "    \n",
    "    #create and insert tags in tags_f\n",
    "    row['tags_f'] = tagging_other(female)\n",
    "    \n",
    "    #create and insert tags in tags_f\n",
    "    row['tags_other'] = tagging_other(other)\n",
    "    \n",
    "    #create, sort, insert tags in tags_c \n",
    "    from operator import itemgetter, attrgetter    \n",
    "    row['tags_c'] = tagging_c(word_list)[0]\n",
    "    row['sum_wgts_c'] = tagging_c(word_list)[1]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not being sure that the text contains violence against women, we joint tags_b and tags_a \n",
    "### and then tags_b and tags_c. \n",
    "### Tags_ab confirm for sure violence against women \n",
    "### Tags_bc helps understand if the story is related to women\n",
    "\n",
    "#row by row\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # if row has tags_a \n",
    "    if len(row['tags_ab']) != 0:\n",
    "        #merging tags_a and tags_b in \n",
    "        row['tags_ab'] =  list(dict.fromkeys(row['tags_ab']+row['tags_b']))  \n",
    "    #sum weights A with weights B \n",
    "    row['sum_wgts_ab'] = row['sum_wgts_a'] + row['sum_wgts_b']\n",
    "    \n",
    "    # if row has tags_b \n",
    "    if len(row['tags_bc']) != 0:\n",
    "        #merging tags_b and tags_c in \n",
    "        row['tags_bc'] =  list(dict.fromkeys(row['tags_bc']+row['tags_c']))  \n",
    "    #sum weights A with weights B \n",
    "    row['sum_wgts_bc'] = row['sum_wgts_b'] + row['sum_wgts_c']\n",
    "    \n",
    "    #all together\n",
    "    #row['tot_tags'] = list(dict.fromkeys(row['tags_ab']+row['tags_bc']+row['tags_c']))  \n",
    "    row['tot_tags'] = list(dict.fromkeys(row['tags_a']+row['tags_b']+row['tags_c']))\n",
    "    \n",
    "    #sum weights A with weights B \n",
    "    cou = len(Counter(row['body'].split()))\n",
    "    row['tot_wgts'] = row['sum_wgts_a'] + row['sum_wgts_b'] + row['sum_wgts_c']\n",
    "    \n",
    "    #by text length criteria\n",
    "    #row['text_len_criteria'] = (row['tot_wgts']/cou)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In and out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem: to sort records by whether they relate to violence against women or otherwise\n",
    "\n",
    "## solution: \n",
    "\n",
    "## - A identifies records that are definitely violence against women\n",
    "## - B identifies records that are almost certainly violence against women\n",
    "## - C identifies records that are perhaps violence against women\n",
    "## - D identifies records that does not seem violence against wome\n",
    "## - E identifies records that are not violence against women\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    \n",
    "    #A(definitely violence against women)\n",
    "    if len(row['tags_a']) != 0:\n",
    "        row['inout'] = 'A = definitely violence against women'\n",
    " \n",
    "    #B(almost certainly violence against women)\n",
    "    elif len(row['tags_a']) == 0 and len(row['tags_b']) !=0 and len(row['tags_f']) != 0:\n",
    "        row['inout'] = 'B = almost certainly violence against women'\n",
    "\n",
    "    #C(perhaps violence against women)\n",
    "    elif len(row['tags_a']) == 0 and len(row['tags_b']) != 0 and len(row['tags_f']) == 0 and len(row['tags_c']) != 0:\n",
    "        row['inout'] = 'C = perhaps violence against women' \n",
    "\n",
    "    #D(it does not seem violence against women)\n",
    "    elif len(row['tags_a']) == 0 and len(row['tags_b']) == 0 and len(row['tags_f']) != 0 and len(row['tags_c']) != 0:\n",
    "        row['inout'] = 'D = it does not seem violence against women'     \n",
    "\n",
    "    #should not be violence against women\n",
    "    else: row['inout'] = 'E = it is not violence against women' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In & Out -- new dataframe of selected columns: sort, save and report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem: how to enable human control\n",
    "\n",
    "## solution: \n",
    "## 1. reports\n",
    "## 2. realtime control "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New dataframe\n",
    "df1 = df[['body','inout','tags_a','tags_b','tags_f','tags_c','tags_other','tot_tags','tot_wgts']]\n",
    "\n",
    "#sort values\n",
    "df1.sort_values(['inout','tot_wgts'], ascending=[True, False], inplace=True)\n",
    "df1_n = df1.to_csv('YT_inout.csv')\n",
    "\n",
    "#report by name\n",
    "\n",
    "name = ('YT_REPORT_inout_'+datetime.now().strftime('_%d-%m-%d_%H-%M-%S')+'.txt')\n",
    "print(name)\n",
    "rep = df_report(name, df1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. realtime control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In & Out -- human_control\n",
    "human_control('YT_inout.csv', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In & Out -- dropping columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem: delete records not relevant to our purpose\n",
    "\n",
    "## solution: drop the records according to the report index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ind_lst = []\n",
    "drop_row(ind_lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the cleaned dataframe\n",
    "f_name = ('YT_priotized_cleaned_'+datetime.now().strftime('_%d-%m-%d_%H-%M-%S')+'.csv')\n",
    "print(f_name)\n",
    "save_df(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying\n",
    "\n",
    "## at this point we have a dataset of informative records that we can query and with which it is possible to filter and cross data and make reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tot_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tot_string_tags'] = [','.join(map(str, l)) for l in df['tot_tags']]\n",
    "df['tot_string_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom_viol = df[df['tot_string_tags'].str.contains('domestic violence') & df['tot_string_tags'].str.contains('help')]\n",
    "dom_viol1 = df[df['tot_string_tags'].str.contains('domestic violence')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, dom_viol.shape, dom_viol1.shape)\n",
    "print()\n",
    "print('---------')\n",
    "print(df.info())\n",
    "print()\n",
    "print('---------')\n",
    "print(dom_viol.info())\n",
    "print()\n",
    "print('---------')\n",
    "print(dom_viol1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted dataframe by ...\n",
    "#sort_by('in&out')\n",
    "#sort_by('priority')\n",
    "#sort_by('sum_wgts_a')\n",
    "#sort_by('sum_wgts_b')\n",
    "#sort_by('sum_wgts_c')\n",
    "#sort_by('tot_wgts')\n",
    "#sort_by('text_len_criteria')\n",
    "\n",
    "#df.sort_values(['priority','tot_wgts'], ascending=[True, False], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting  and reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create report by name\n",
    "df.sort_values(['priority','tot_wgts'], ascending=[True, False], inplace=True)\n",
    "df_report('YT_REPORT_5.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the cleaned dataframe\n",
    "save_df('FB_cleaned_priotized_transcripts.csv')\n",
    "#save_df('youtube_cleaned_transcripts1.csv')\n",
    "#save_df('youtube_cleaned_transcripts2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#human_control(youtube_cleaned_transcripts.csv, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## we have a dataset of informative records that we can query and with which it is possible to filter and cross data and make reports\n",
    "\n",
    "## we have created a dictionary of relevant single words and n-grams of two, three or more words (typical sentences used) from databasets or corpora\n",
    "\n",
    "## we have a server-side system to allow human control\n",
    "\n",
    "## This tool is already able to identify and prioritize forms of violence against women\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT STEPS\n",
    "\n",
    "## within next week:\n",
    "\n",
    "## - to improve weights by grouping tags\n",
    "\n",
    "## - to make a single dataset of selected records \n",
    "\n",
    "## - to try a supervised classification method\n",
    "\n",
    "## within two weeks:\n",
    "\n",
    "## - to check results, refine and put all together\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctives:\n",
    "- using verbs\n",
    "- relationships with geography and diseases (hiv, aids, etc.. )\n",
    "- improve weights by grouping tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task6_lin.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "82a93e9466893ddaf289fff1961ea299444cd32d807a5b56a48ff36194f49996"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}